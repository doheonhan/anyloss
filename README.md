# AnyLoss

### 1. Pure Code Review
* AnyLoss - Code.ipynb
### 2. 4 datasets
* 4-10: (MSE/BCE/AnyLoss) Performance on 4 Datasets - SLP
* 4-13: (SOL) Performance on 4 datasets - SLP
* 4-20: (MSE/BCE/AnyLoss) Performance on 4 Datasets - MLP
* 4-22: (SOL) Performance on 4 Datasets - MLP
### 3. 102 datasets
* 4-30: (MSE/BCE/AnyLoss) Performance on 102 Datasets - SLP
* 4-40: (MSE/BCE/AnyLoss) Performance on 102 Datasets - MLP
### 4. Comparison with Resampling Strategy
* 4-11: (BCE_SMOTE/BCE_RandomUndersampling/AnyLoss) Comparison on 4 Datasets - SLP
### 5. Learning Speed
* 4-51: (MSE/BCE/AnyLoss) Learning Speed on 4 Datasets - SLP
* 4-52: (SOL) Learning Speed on 4 Datasets - SLP
* 4-62: (MSE/BCE/AnyLoss/SOL) Learning Speed on 4 Datasets - MLP
### 6. Misc.
* 4 datasets (breast_cancer, diabetes_prediction_dataset) and others are too big to upload.
* 102 datasets: data_num
* Bayesian Sign Test: bayesiantests.py and BAYES_Mine.ipynb
* Additional Information for the paper
  
[Description of 102 Diverse Datasets]
  
| **Dataset** | **#Sample** | **#Feature** | **Class Dist ('0':'1')** | **Dataset** | **#Sample** | **#Feature** | **Class Dist ('0':'1')** |
|:--------:|:--------:|:---------:|:--------:|:--------:|:--------:|:---------:|:--------:|
|	1	|	250	|	12	|	0.64	:	0.36	|	52	|	990	|	13	|	0.91	:	0.09	|
|	2	|	250	|	9	|	0.62	:	0.38	|	53	|	1000	|	19	|	0.70	:	0.30    |
|	3	|	306	|	3	|	0.74	:	0.26	|   54	|	1000	|	20	|	0.74	:	0.26    |
|	4	|	310	|	6	|	0.68	:	0.32	|	55	|	1043	|	37	|	0.88	:	0.12	|
|	5	|	320	|	6	|	0.67	:	0.33	|	56	|	1055	|	32	|	0.66	:	0.34	|
|	6	|	327	|	37	|	0.87	:	0.13	|	57	|	1066	|	7	|	0.83	:	0.17	|
|	7	|	328	|	32	|	0.69	:	0.31	|	58	|	1074	|	16	|	0.68	:	0.32	|
|	8	|	335	|	3	|	0.85	:	0.15	|	59	|	1077	|	37	|	0.88	:	0.12	|
|	9	|	336	|	14	|	0.76	:	0.24	|	60	|	1109	|	21	|	0.93	:	0.07	|
|	10	|	349	|	31	|	0.62	:	0.38	|	61	|	1156	|	5	|	0.78	:	0.22	|
|	11	|	351	|	33	|	0.64	:	0.36    |	62	|	1320	|	17	|	0.91	:	0.09	|
|	12	|	358	|	31	|	0.69	:	0.31	|	63	|	1324	|	10	|	0.78	:	0.22	|
|	13	|	363	|	8	|	0.77	:	0.23	|	64	|	1458	|	37	|	0.88	:	0.12	|
|	14	|	365	|	5	|	0.92	:	0.08	|	65	|	1563	|	37	|	0.90	:	0.10	|
|	15	|	381	|	38	|	0.85	:	0.15	|	66	|	1728	|	6	|	0.70	:	0.30	|
|	16	|	392	|	8	|	0.62	:	0.38	|	67	|	1941	|	31	|	0.65	:	0.35	|
|	17	|	400	|	5	|	0.78	:	0.22	|	68	|	2000	|	6	|	0.90	:	0.10	|
|	18	|	403	|	35	|	0.92	:	0.08	|	69	|	2000	|	76	|	0.90	:	0.10	|
|	19	|	450	|	3	|	0.88	:	0.12	|	70	|	2000	|	216	|	0.90	:	0.10	|
|	20	|	458	|	38	|	0.91	:	0.09	|	71	|	2000	|	47	|	0.90	:	0.10	|
|	21	|	462	|	9	|	0.65	:	0.35	|	72	|	2000	|	64	|	0.90	:	0.10	|
|	22	|	470	|	13	|	0.85	:	0.15	|	73	|	2000	|	239	|	0.90	:	0.10	|
|	23	|	475	|	3	|	0.87	:	0.13	|	74	|	2000	|	139	|	0.72	:	0.28	|
|	24	|	475	|	3	|	0.87	:	0.13	|	75	|	2000	|	140	|	0.87	:	0.13	|
|	25	|	500	|	25	|	0.61	:	0.39	|	76	|	2001	|	2	|	0.76	:	0.24	|
|	26	|	500	|	22	|	0.84	:	0.16	|	77	|	2109	|	20	|	0.85	:	0.15	|
|	27	|	504	|	19	|	0.91	:	0.09	|	78	|	2201	|	2	|	0.68	:	0.32	|
|	28	|	522	|	20	|	0.80	:	0.20	|	79	|	2310	|	17	|	0.86	:	0.14	|
|	29	|	531	|	101	|	0.90	:	0.10	|	80	|	2407	|	299	|	0.82	:	0.18	|
|	30	|	540	|	20	|	0.91	:	0.09	|	81	|	2417	|	115	|	0.74	:	0.26	|
|	31	|	559	|	4	|	0.86	:	0.14	|	82	|	2534	|	71	|	0.94	:	0.06	|
|	32	|	562	|	21	|	0.84	:	0.16	|	83	|	3103	|	12	|	0.93	:	0.07	|
|	33	|	569	|	30	|	0.63	:	0.37	|	84	|	3103	|	12	|	0.92	:	0.08	|
|	34	|	583	|	10	|	0.71	:	0.29	|	85	|	4052	|	5	|	0.76	:	0.24	|
|	35	|	593	|	77	|	0.68	:	0.32	|	86	|	4474	|	11	|	0.75	:	0.25	|
|	36	|	600	|	61	|	0.83	:	0.17	|	87	|	4521	|	14	|	0.88	:	0.12	|
|	37	|	609	|	7	|	0.63	:	0.37	|	88	|	4601	|	7	|	0.61	:	0.39	|
|	38	|	641	|	19	|	0.68	:	0.32	|	89	|	4859	|	120	|	0.83	:	0.17	|
|	39	|	645	|	168	|	0.94	:	0.06	|	90	|	5000	|	40	|	0.66	:	0.34	|
|	40	|	661	|	37	|	0.92	:	0.08	|	91	|	5000	|	19	|	0.86	:	0.14	|
|	41	|	683	|	9	|	0.65	:	0.35	|	92	|	5404	|	5	|	0.71	:	0.29	|
|	42	|	705	|	37	|	0.91	:	0.09	|	93	|	5473	|	10	|	0.90	:	0.10	|
|	43	|	748	|	4	|	0.76	:	0.24	|	94	|	5620	|	48	|	0.90	:	0.10	|
|	44	|	768	|	8	|	0.65	:	0.35	|	95	|	6598	|	169	|	0.85	:	0.15	|
|	45	|	797	|	4	|	0.81	:	0.19	|	96	|	6598	|	168	|	0.85	:	0.15	|
|	46	|	812	|	6	|	0.77	:	0.23	|	97	|	7032	|	36	|	0.89	:	0.11	|
|	47	|	841	|	70	|	0.62	:	0.38	|	98	|	7970	|	39	|	0.93	:	0.07	|
|	48	|	846	|	18	|	0.74	:	0.26	|	99	|	8192	|	12	|	0.70	:	0.30	|
|	49	|	958	|	9	|	0.65	:	0.35	|	100	|	8192	|	19	|	0.70	:	0.30	|
|	50	|	959	|	40	|	0.64	:	0.36	|	101	|	8192	|	32	|	0.69	:	0.31	|
|	51	|	973	|	9	|	0.67	:	0.33	|	102	|	9961	|	14	|	0.84	:	0.16	|
